#!/usr/bin/env python3
"""
æµ‹è¯•æ”¹è¿›CRNNæ¨¡å‹
åŸºäºæ™ºèƒ½åå¤„ç†æ¨ç†ï¼Œä½¿ç”¨æ–°è®­ç»ƒçš„æ”¹è¿›æ¨¡å‹
"""

import os
import cv2
import numpy as np
import pandas as pd
from PIL import Image
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from ultralytics import YOLO
import re

# é…ç½®å‚æ•°
VAL_IMAGES_DIR = './yolov8_dataset/images/val'
LABEL_FILE = './Dataset/labels.csv'
YOLO_MODEL_PATH = './runs/detect/meter_detection/weights/best.pt'
CRNN_MODEL_PATH = './crnn_improved_best.pth'  # ä½¿ç”¨æ”¹è¿›çš„æœ€ä½³æ¨¡å‹
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹å®Œå…¨ä¸€è‡´çš„å‚æ•°
IMG_HEIGHT = 64
IMG_WIDTH = 256
HIDDEN_SIZE = 256  # ä¿æŒ256
NUM_LAYERS = 2
CHARS = '0123456789.'
BLANK_IDX = len(CHARS)
idx2char = {i: c for i, c in enumerate(CHARS)}

class ImprovedCRNN(nn.Module):
    """æ”¹è¿›çš„CRNN - ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´"""
    
    def __init__(self, img_h, n_channels, n_hidden, n_classes):
        super().__init__()
        
        # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹å®Œå…¨ä¸€è‡´çš„CNNæ¶æ„
        self.cnn = nn.Sequential(
            nn.Conv2d(n_channels, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2, 2),
            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(),
            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(512, 512, 2, 1, 0), nn.BatchNorm2d(512), nn.ReLU()
        )
        
        # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹å®Œå…¨ä¸€è‡´çš„RNNæ¶æ„
        self.rnn = nn.LSTM(512, n_hidden, num_layers=2, bidirectional=True, batch_first=True, dropout=0.1)
        
        # ğŸ¯ ä¿æŒç®€å•çš„è¾“å‡ºå±‚
        self.fc = nn.Linear(n_hidden * 2, n_classes + 1)

    def forward(self, x):
        # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹å®Œå…¨ä¸€è‡´çš„å‰å‘ä¼ æ’­
        conv = self.cnn(x)
        conv = F.adaptive_avg_pool2d(conv, (1, conv.size(3)))
        seq = conv.squeeze(2).permute(0, 2, 1)
        rnn_out, _ = self.rnn(seq)
        logits = self.fc(rnn_out)
        return logits.permute(1, 0, 2)

def decode_ctc_greedy(output, blank_idx=BLANK_IDX):
    """ğŸ¯ ä¿æŒä¸æ™ºèƒ½åå¤„ç†å®Œå…¨ä¸€è‡´çš„CTCè§£ç """
    predictions = torch.argmax(output, dim=2).squeeze(1).cpu().numpy()
    
    result = []
    prev_idx = -1
    
    for idx in predictions:
        if idx != blank_idx and idx != prev_idx:
            if idx < len(idx2char):
                result.append(idx2char[idx])
        prev_idx = idx
    
    return ''.join(result)

class SmartPostProcessor:
    """ğŸ¯ ä¸æ™ºèƒ½åå¤„ç†å®Œå…¨ä¸€è‡´çš„åå¤„ç†å™¨"""
    
    def __init__(self):
        # ç”µè¡¨è¯»æ•°çš„å¸¸è§æ¨¡å¼
        self.common_patterns = [
            r'^\d{1,6}\.\d{1,2}$',  # æ ‡å‡†æ ¼å¼: 1234.5
            r'^\d{1,6}$',           # æ•´æ•°æ ¼å¼: 1234
        ]
    
    def smart_clean(self, text):
        """æ™ºèƒ½æ¸…ç†å’Œæ ¼å¼åŒ–"""
        if not text:
            return ""
        
        # æ­¥éª¤1: åŸºç¡€æ¸…ç† - åªä¿ç•™æ•°å­—å’Œå°æ•°ç‚¹
        cleaned = ''.join(c for c in text if c.isdigit() or c == '.')
        
        if not cleaned:
            return ""
        
        # æ­¥éª¤2: å¤„ç†å¤šä¸ªè¿ç»­å°æ•°ç‚¹
        cleaned = re.sub(r'\.{2,}', '.', cleaned)  # å¤šä¸ªç‚¹å˜æˆä¸€ä¸ª
        
        # æ­¥éª¤3: å¤„ç†å°¾éƒ¨å°æ•°ç‚¹ - å…³é”®ä¿®å¤ï¼
        if cleaned.endswith('.'):
            # å¦‚æœä»¥ç‚¹ç»“å°¾ï¼Œåˆ é™¤å°¾éƒ¨ç‚¹
            cleaned = cleaned.rstrip('.')
        
        # æ­¥éª¤4: å¤„ç†å¼€å¤´å°æ•°ç‚¹
        if cleaned.startswith('.'):
            cleaned = '0' + cleaned
        
        # æ­¥éª¤5: å¤„ç†å¤šä¸ªå°æ•°ç‚¹
        if cleaned.count('.') > 1:
            # ä¿ç•™ç¬¬ä¸€ä¸ªå°æ•°ç‚¹ï¼Œå…¶ä½™å˜æˆæ•°å­—
            parts = cleaned.split('.')
            if len(parts) > 2:
                # ä¾‹å¦‚: "12.34.56" -> "12.3456"
                cleaned = parts[0] + '.' + ''.join(parts[1:])
        
        # æ­¥éª¤6: å¤„ç†å‰å¯¼é›¶
        if cleaned and not cleaned.startswith('.'):
            if '.' in cleaned:
                integer_part, decimal_part = cleaned.split('.', 1)
                integer_part = integer_part.lstrip('0') or '0'
                # ä¿ç•™æ‰€æœ‰å°æ•°ä½ï¼Œä¸åˆ é™¤å°¾éƒ¨0
                cleaned = f"{integer_part}.{decimal_part}"
            else:
                cleaned = cleaned.lstrip('0') or '0'
        
        # æ­¥éª¤7: éªŒè¯æ ¼å¼åˆç†æ€§
        if not self.is_reasonable_meter_reading(cleaned):
            # å¦‚æœæ ¼å¼ä¸åˆç†ï¼Œå°è¯•ä¿®å¤
            cleaned = self.try_fix_format(cleaned)
        
        return cleaned
    
    def is_reasonable_meter_reading(self, text):
        """æ£€æŸ¥æ˜¯å¦æ˜¯åˆç†çš„ç”µè¡¨è¯»æ•°æ ¼å¼"""
        if not text:
            return False
        
        # åŸºæœ¬æ ¼å¼æ£€æŸ¥
        for pattern in self.common_patterns:
            if re.match(pattern, text):
                return True
        
        # é•¿åº¦æ£€æŸ¥ (ç”µè¡¨è¯»æ•°é€šå¸¸ä¸ä¼šå¤ªé•¿)
        if len(text) > 10:  # è¶…è¿‡10ä½å¯èƒ½æœ‰é—®é¢˜
            return False
        
        # å°æ•°ä½æ£€æŸ¥ (é€šå¸¸ä¸è¶…è¿‡2ä½å°æ•°)
        if '.' in text:
            decimal_part = text.split('.')[1]
            if len(decimal_part) > 2:
                return False
        
        return True
    
    def try_fix_format(self, text):
        """å°è¯•ä¿®å¤å¼‚å¸¸æ ¼å¼"""
        if not text:
            return text
        
        # å¦‚æœå°æ•°éƒ¨åˆ†å¤ªé•¿ï¼Œæˆªæ–­åˆ°2ä½
        if '.' in text:
            integer_part, decimal_part = text.split('.', 1)
            if len(decimal_part) > 2:
                decimal_part = decimal_part[:2]
                text = f"{integer_part}.{decimal_part}"
        
        return text
    
    def process_prediction(self, raw_prediction):
        """å¤„ç†å•ä¸ªé¢„æµ‹ç»“æœ"""
        if not raw_prediction:
            return ""
        
        # æ™ºèƒ½æ¸…ç†
        cleaned = self.smart_clean(raw_prediction)
        
        return cleaned

def smart_bbox_fallback(yolo_results, true_bbox, img_w=400, img_h=296):
    """ğŸ¯ ä¸æ™ºèƒ½åå¤„ç†å®Œå…¨ä¸€è‡´çš„è¾¹ç•Œæ¡†é€‰æ‹©"""
    if len(yolo_results[0].boxes) > 0:
        box = yolo_results[0].boxes[0]
        confidence = float(box.conf[0])
        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
        
        width = x2 - x1
        height = y2 - y1
        
        if confidence < 0.3 or width < 20 or height < 10 or width > 300 or height > 100:
            x1, y1, x2, y2 = true_bbox
            source = "çœŸå®æ¡†(YOLOä½è´¨é‡)"
        else:
            source = f"YOLO(ç½®ä¿¡åº¦{confidence:.2f})"
    else:
        x1, y1, x2, y2 = true_bbox
        source = "çœŸå®æ¡†(YOLOæ— æ£€æµ‹)"
    
    return int(x1), int(y1), int(x2), int(y2), source

def test_improved_model():
    """æµ‹è¯•æ”¹è¿›CRNNæ¨¡å‹"""
    print("ğŸš€ æ”¹è¿›CRNNæ¨¡å‹æµ‹è¯• - æ–¹æ¡ˆB")
    print("åŸºäº79.76%æ™ºèƒ½åå¤„ç†ï¼Œä½¿ç”¨æ”¹è¿›çš„CRNNæ¨¡å‹")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(CRNN_MODEL_PATH):
        print(f"âŒ æ”¹è¿›æ¨¡å‹ä¸å­˜åœ¨: {CRNN_MODEL_PATH}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ train_crnn_improved.py è®­ç»ƒæ¨¡å‹")
        return
    
    # åŠ è½½YOLOæ¨¡å‹
    try:
        yolo_model = YOLO(YOLO_MODEL_PATH)
        print("âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # åŠ è½½æ”¹è¿›çš„CRNNæ¨¡å‹
    try:
        crnn_model = ImprovedCRNN(IMG_HEIGHT, 1, HIDDEN_SIZE, len(CHARS)).to(DEVICE)
        crnn_model.load_state_dict(torch.load(CRNN_MODEL_PATH, map_location=DEVICE))
        crnn_model.eval()
        print("âœ… æ”¹è¿›CRNNæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥æ¨¡å‹å¤§å°
        model_size = sum(p.numel() for p in crnn_model.parameters()) / 1e6
        print(f"ğŸ“ æ¨¡å‹å¤§å°: {model_size:.1f}M å‚æ•°")
    except Exception as e:
        print(f"âŒ CRNNæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # åŠ è½½éªŒè¯æ•°æ®
    df = pd.read_csv(LABEL_FILE)
    val_images = set(os.listdir(VAL_IMAGES_DIR))
    val_data = df[df['filename'].isin(val_images)].reset_index(drop=True)
    print(f"ğŸ“Š éªŒè¯é›†æ ·æœ¬æ•°: {len(val_data)}")
    
    # ğŸ¯ ä¿æŒä¸æ™ºèƒ½åå¤„ç†å®Œå…¨ä¸€è‡´çš„å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    
    # åˆå§‹åŒ–æ™ºèƒ½åå¤„ç†å™¨
    postprocessor = SmartPostProcessor()
    
    print(f"\nğŸ” å¼€å§‹æ”¹è¿›æ¨¡å‹æ¨ç†...")
    
    correct_predictions = 0
    total_predictions = 0
    yolo_used = 0
    fallback_used = 0
    postprocess_fixes = 0
    
    predictions_data = []
    
    for idx, row in val_data.iterrows():
        filename = row['filename']
        true_number = str(row['number'])
        img_path = os.path.join(VAL_IMAGES_DIR, filename)
        
        # åŠ è½½å›¾åƒ
        image = cv2.imread(img_path)
        if image is None:
            continue
        
        # YOLOæ£€æµ‹
        results = yolo_model(image, verbose=False)
        
        # æ™ºèƒ½è¾¹ç•Œæ¡†é€‰æ‹©
        true_bbox = (int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax']))
        x1, y1, x2, y2, bbox_source = smart_bbox_fallback(results, true_bbox)
        
        if "YOLO" in bbox_source:
            yolo_used += 1
        else:
            fallback_used += 1
        
        # æå–æ•°å­—åŒºåŸŸ
        digit_region = image[y1:y2, x1:x2]
        if digit_region.size == 0:
            continue
        
        # é¢„å¤„ç†æ•°å­—åŒºåŸŸ
        digit_gray = cv2.cvtColor(digit_region, cv2.COLOR_BGR2GRAY)
        pil_image = Image.fromarray(digit_gray)
        image_tensor = transform(pil_image).unsqueeze(0).to(DEVICE)
        
        # CRNNæ¨ç†
        with torch.no_grad():
            outputs = crnn_model(image_tensor)
            raw_prediction = decode_ctc_greedy(outputs)
        
        # æ™ºèƒ½åå¤„ç†
        original_prediction = raw_prediction
        processed_prediction = postprocessor.process_prediction(raw_prediction)
        
        # æ£€æŸ¥æ˜¯å¦è¢«åå¤„ç†ä¿®å¤
        postprocess_info = ""
        if original_prediction != processed_prediction:
            postprocess_fixes += 1
            postprocess_info = f" [åŸå§‹='{original_prediction}']"
        
        # åˆ¤æ–­å‡†ç¡®æ€§
        is_correct = processed_prediction == true_number
        if is_correct:
            correct_predictions += 1
        
        total_predictions += 1
        
        # è®°å½•é¢„æµ‹ç»“æœ
        predictions_data.append({
            'filename': filename,
            'predicted': processed_prediction,
            'actual': true_number,
            'correct': is_correct,
            'bbox_source': bbox_source,
            'raw_prediction': original_prediction
        })
        
        # æ˜¾ç¤ºç»“æœï¼ˆåªæ˜¾ç¤ºå‰40ä¸ªå’Œé”™è¯¯æ¡ˆä¾‹ï¼‰
        status = "âœ…" if is_correct else "âŒ"
        if idx < 40 or not is_correct:
            print(f"{filename}: é¢„æµ‹='{processed_prediction}' | çœŸå®='{true_number}' | {bbox_source}{postprocess_info} | {status}")
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = (correct_predictions / total_predictions * 100) if total_predictions > 0 else 0
    
    print(f"\n" + "=" * 60)
    print(f"ğŸ“Š æ”¹è¿›CRNNæ¨¡å‹å‡†ç¡®ç‡: {accuracy:.2f}% ({correct_predictions}/{total_predictions})")
    print(f"ğŸ“ è¾¹ç•Œæ¡†ä½¿ç”¨: YOLO={yolo_used}, å›é€€={fallback_used}")
    print(f"ğŸ”§ åå¤„ç†ä¿®å¤: {postprocess_fixes}ä¸ªæ¡ˆä¾‹")
    
    # ä¸åŸºçº¿æ¯”è¾ƒ
    baseline_accuracy = 79.76
    improvement = accuracy - baseline_accuracy
    if improvement > 0:
        print(f"ğŸ“ˆ ç›¸æ¯”åŸºçº¿æå‡: +{improvement:.2f}%")
        print(f"âœ¨ æ”¹è¿›æˆåŠŸï¼")
        if accuracy >= 85:
            print(f"ğŸ‰ è¾¾åˆ°85%+ç›®æ ‡ï¼")
    elif improvement < -1:
        print(f"ğŸ“‰ ç›¸æ¯”åŸºçº¿ä¸‹é™: {improvement:.2f}%")
        print(f"âš ï¸ æ”¹è¿›æœªè¾¾é¢„æœŸ")
    else:
        print(f"ğŸ“Š ä¸åŸºçº¿åŸºæœ¬æŒå¹³: {improvement:+.2f}%")
    
    print(f"ğŸ¯ è·ç¦»90%ç›®æ ‡è¿˜å·®: {90 - accuracy:.2f}%")
    
    # ä¿å­˜ç»“æœ
    results_file = 'validation_predictions_improved.csv'
    pd.DataFrame(predictions_data).to_csv(results_file, index=False)
    print(f"ğŸ’¾ ä¿å­˜ç»“æœåˆ°: {results_file}")
    print(f"âœ… æ”¹è¿›CRNNæ¨¡å‹æµ‹è¯•å®Œæˆ")

if __name__ == '__main__':
    test_improved_model() 