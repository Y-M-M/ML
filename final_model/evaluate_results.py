#!/usr/bin/env python3
"""
å¯¹æ¯”é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾ï¼Œè®¡ç®—å‡†ç¡®ç‡
"""

import pandas as pd
import os

# é…ç½®å‚æ•°
PREDICTIONS_FILE = './results.csv'
LABELS_FILE = '/Volumes/YMM/Dataset/labels.csv'

def evaluate_predictions():
    """å¯¹æ¯”é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾"""
    print("ğŸ” å¼€å§‹è¯„ä¼°é¢„æµ‹ç»“æœ...")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(PREDICTIONS_FILE):
        print(f"âŒ é¢„æµ‹ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {PREDICTIONS_FILE}")
        return
    
    if not os.path.exists(LABELS_FILE):
        print(f"âŒ æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {LABELS_FILE}")
        return
    
    try:
        # è¯»å–é¢„æµ‹ç»“æœ (æ²¡æœ‰è¡¨å¤´)
        predictions_df = pd.read_csv(PREDICTIONS_FILE, header=None, names=['id', 'predicted_reading'])
        print(f"âœ… é¢„æµ‹ç»“æœåŠ è½½æˆåŠŸï¼Œå…± {len(predictions_df)} æ¡è®°å½•")
        
        # è¯»å–çœŸå®æ ‡ç­¾
        labels_df = pd.read_csv(LABELS_FILE)
        print(f"âœ… æ ‡ç­¾æ–‡ä»¶åŠ è½½æˆåŠŸï¼Œå…± {len(labels_df)} æ¡è®°å½•")
        
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶æ˜¯å¦åŒ…å«numberåˆ—
    if 'number' not in labels_df.columns:
        print(f"âŒ æ ‡ç­¾æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° 'number' åˆ—")
        print(f"   å¯ç”¨åˆ—: {list(labels_df.columns)}")
        return
    
    # ç¡®ä¿ä¸¤ä¸ªæ•°æ®é›†çš„é•¿åº¦ä¸€è‡´
    min_length = min(len(predictions_df), len(labels_df))
    if len(predictions_df) != len(labels_df):
        print(f"âš ï¸  æ•°æ®é›†é•¿åº¦ä¸ä¸€è‡´: é¢„æµ‹ç»“æœ {len(predictions_df)} vs æ ‡ç­¾ {len(labels_df)}")
        print(f"   å°†ä½¿ç”¨å‰ {min_length} æ¡è®°å½•è¿›è¡Œæ¯”è¾ƒ")
    
    # æˆªå–ç›¸åŒé•¿åº¦çš„æ•°æ®
    predictions_df = predictions_df.head(min_length)
    labels_df = labels_df.head(min_length)
    
    # æå–çœŸå®è¯»æ•°
    true_readings = labels_df['number'].astype(str)
    predicted_readings = predictions_df['predicted_reading'].astype(str)
    
    # è®¡ç®—å‡†ç¡®ç‡
    correct_predictions = 0
    total_predictions = len(predictions_df)
    
    # è¯¦ç»†æ¯”è¾ƒç»“æœ
    comparison_results = []
    
    for i in range(total_predictions):
        true_val = true_readings.iloc[i]
        pred_val = predicted_readings.iloc[i]
        
        # ç²¾ç¡®åŒ¹é…
        is_correct = (true_val == pred_val)
        
        if is_correct:
            correct_predictions += 1
        
        comparison_results.append({
            'id': i + 1,
            'true_reading': true_val,
            'predicted_reading': pred_val,
            'correct': is_correct
        })
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = correct_predictions / total_predictions * 100
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"   æ€»æ ·æœ¬æ•°: {total_predictions}")
    print(f"   é¢„æµ‹æ­£ç¡®: {correct_predictions}")
    print(f"   é¢„æµ‹é”™è¯¯: {total_predictions - correct_predictions}")
    print(f"   å‡†ç¡®ç‡: {accuracy:.2f}%")
    
    # æ˜¾ç¤ºä¸€äº›é”™è¯¯æ¡ˆä¾‹
    incorrect_cases = [case for case in comparison_results if not case['correct']]
    
    if incorrect_cases:
        print(f"\nâŒ é”™è¯¯æ¡ˆä¾‹ (å‰10ä¸ª):")
        for i, case in enumerate(incorrect_cases[:10]):
            print(f"   ID {case['id']}: çœŸå®={case['true_reading']}, é¢„æµ‹={case['predicted_reading']}")
    
    # æ˜¾ç¤ºä¸€äº›æ­£ç¡®æ¡ˆä¾‹
    correct_cases = [case for case in comparison_results if case['correct']]
    
    if correct_cases:
        print(f"\nâœ… æ­£ç¡®æ¡ˆä¾‹ (å‰5ä¸ª):")
        for i, case in enumerate(correct_cases[:5]):
            print(f"   ID {case['id']}: çœŸå®={case['true_reading']}, é¢„æµ‹={case['predicted_reading']}")
    
    # ä¿å­˜è¯¦ç»†æ¯”è¾ƒç»“æœ
    comparison_df = pd.DataFrame(comparison_results)
    comparison_output = './comparison_results.csv'
    comparison_df.to_csv(comparison_output, index=False)
    print(f"\nğŸ’¾ è¯¦ç»†æ¯”è¾ƒç»“æœå·²ä¿å­˜åˆ°: {comparison_output}")
    
    # æ•°å€¼åˆ†æ (å°è¯•å°†è¯»æ•°è½¬æ¢ä¸ºæ•°å€¼è¿›è¡Œæ›´è¯¦ç»†çš„åˆ†æ)
    print(f"\nğŸ”¢ æ•°å€¼åˆ†æ:")
    try:
        true_numeric = pd.to_numeric(true_readings, errors='coerce')
        pred_numeric = pd.to_numeric(predicted_readings, errors='coerce')
        
        # è¿‡æ»¤æ‰æ— æ³•è½¬æ¢ä¸ºæ•°å€¼çš„æ•°æ®
        valid_mask = ~(true_numeric.isna() | pred_numeric.isna())
        true_numeric_valid = true_numeric[valid_mask]
        pred_numeric_valid = pred_numeric[valid_mask]
        
        if len(true_numeric_valid) > 0:
            # è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·®
            mae = abs(true_numeric_valid - pred_numeric_valid).mean()
            print(f"   æœ‰æ•ˆæ•°å€¼æ ·æœ¬: {len(true_numeric_valid)}")
            print(f"   å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.4f}")
            
            # è®¡ç®—åœ¨ä¸€å®šè¯¯å·®èŒƒå›´å†…çš„å‡†ç¡®ç‡
            tolerance_levels = [0.1, 0.5, 1.0]
            for tol in tolerance_levels:
                within_tolerance = abs(true_numeric_valid - pred_numeric_valid) <= tol
                tolerance_accuracy = within_tolerance.sum() / len(true_numeric_valid) * 100
                print(f"   è¯¯å·® â‰¤ {tol} çš„å‡†ç¡®ç‡: {tolerance_accuracy:.2f}%")
        else:
            print("   æ— æœ‰æ•ˆçš„æ•°å€¼æ•°æ®è¿›è¡Œåˆ†æ")
            
    except Exception as e:
        print(f"   æ•°å€¼åˆ†æå¤±è´¥: {e}")

if __name__ == '__main__':
    evaluate_predictions() 