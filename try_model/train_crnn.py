#!/usr/bin/env python3
"""
CRNNæ”¹è¿›è®­ç»ƒè„šæœ¬ - æ–¹æ¡ˆB
åŸºäº79.76%æœ‰æ•ˆæ¶æ„ï¼Œè¿›è¡Œæœ€å°åŒ–ã€ç»è¿‡éªŒè¯çš„æ”¹è¿›
ç›®æ ‡ï¼šç¨³æ­¥æå‡åˆ°85%+
"""

import os
import csv
import cv2
import numpy as np
from PIL import Image, ImageEnhance
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torch.nn.functional as F
import random
from tqdm import tqdm
import pandas as pd

# é…ç½®å‚æ•°
TRAIN_IMAGES_DIR = './yolov8_dataset/images/train'
VAL_IMAGES_DIR = './yolov8_dataset/images/val'
LABEL_FILE = './Dataset/labels.csv'
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹å®Œå…¨ä¸€è‡´çš„æ ¸å¿ƒå‚æ•°
IMG_HEIGHT = 64
IMG_WIDTH = 256
HIDDEN_SIZE = 256  # ä¿æŒ256ï¼Œä¸æ”¹å˜
NUM_LAYERS = 2
CHARS = '0123456789.'
BLANK_IDX = len(CHARS)
char2idx = {c: i for i, c in enumerate(CHARS)}

# è®­ç»ƒå‚æ•° - ä¿å®ˆæ”¹è¿›
BATCH_SIZE = 16
EPOCHS = 60        # é€‚åº¦å¢åŠ è®­ç»ƒè½®æ•°
LEARNING_RATE = 0.0008  # ç¨å¾®é™ä½å­¦ä¹ ç‡
EARLY_STOP_PATIENCE = 15

class ImprovedCRNN(nn.Module):
    """æ”¹è¿›çš„CRNN - åŸºäºæœ‰æ•ˆæ¶æ„ï¼Œæœ€å°åŒ–æ”¹åŠ¨"""
    
    def __init__(self, img_h, n_channels, n_hidden, n_classes):
        super().__init__()
        
        # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹å®Œå…¨ä¸€è‡´çš„CNNæ¶æ„
        self.cnn = nn.Sequential(
            nn.Conv2d(n_channels, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2, 2),
            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(),
            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(), nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(512, 512, 2, 1, 0), nn.BatchNorm2d(512), nn.ReLU()  # ğŸ¯ ä¿æŒå…³é”®çš„æœ€åä¸€å±‚
        )
        
        # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹å®Œå…¨ä¸€è‡´çš„RNNæ¶æ„
        self.rnn = nn.LSTM(512, n_hidden, num_layers=2, bidirectional=True, batch_first=True, dropout=0.1)
        
        # ğŸ¯ ä¿æŒç®€å•çš„è¾“å‡ºå±‚
        self.fc = nn.Linear(n_hidden * 2, n_classes + 1)

    def forward(self, x):
        # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹å®Œå…¨ä¸€è‡´çš„å‰å‘ä¼ æ’­
        conv = self.cnn(x)
        conv = F.adaptive_avg_pool2d(conv, (1, conv.size(3)))
        seq = conv.squeeze(2).permute(0, 2, 1)
        rnn_out, _ = self.rnn(seq)
        logits = self.fc(rnn_out)
        return logits.permute(1, 0, 2)

class ImprovedDataset(Dataset):
    """æ”¹è¿›çš„æ•°æ®é›† - åŸºäºæœ‰æ•ˆçš„æ•°æ®å¤„ç†ï¼Œæ·»åŠ è½»åº¦å¢å¼º"""
    
    def __init__(self, data, chars, img_h, img_w, training=True):
        self.data = data
        self.chars = chars
        self.char_to_idx = {char: idx for idx, char in enumerate(chars)}
        self.img_h = img_h
        self.img_w = img_w
        self.training = training
        
        # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹ä¸€è‡´çš„åŸºç¡€å˜æ¢
        self.transform = transforms.Compose([
            transforms.Resize((img_h, img_w)),
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])
    
    def __len__(self):
        return len(self.data)
    
    def apply_light_augmentation(self, image):
        """è½»åº¦æ•°æ®å¢å¼º - åªåœ¨è®­ç»ƒæ—¶ä½¿ç”¨"""
        if not self.training or random.random() > 0.25:  # åªæœ‰25%æ¦‚ç‡å¢å¼º
            return image
        
        # éå¸¸ä¿å®ˆçš„å¢å¼º
        if random.random() < 0.5:
            # è½»å¾®å¯¹æ¯”åº¦è°ƒæ•´
            enhancer = ImageEnhance.Contrast(image)
            factor = random.uniform(0.95, 1.05)  # å¾ˆå°çš„å˜åŒ–
            image = enhancer.enhance(factor)
        
        return image
    
    def __getitem__(self, idx):
        item = self.data.iloc[idx]
        
        # åŠ è½½å›¾åƒ
        if self.training:
            img_path = os.path.join(TRAIN_IMAGES_DIR, item['filename'])
        else:
            img_path = os.path.join(VAL_IMAGES_DIR, item['filename'])
        
        image = cv2.imread(img_path)
        if image is None:
            image = np.ones((50, 100, 3), dtype=np.uint8) * 255
        
        # ä½¿ç”¨æ­£ç¡®çš„åˆ—å
        x1, y1, x2, y2 = int(item['xmin']), int(item['ymin']), int(item['xmax']), int(item['ymax'])
        digit_region = image[y1:y2, x1:x2]
        
        if digit_region.size == 0:
            digit_region = np.ones((50, 100, 3), dtype=np.uint8) * 255
        
        # è½¬æ¢ä¸ºç°åº¦
        digit_gray = cv2.cvtColor(digit_region, cv2.COLOR_BGR2GRAY)
        pil_image = Image.fromarray(digit_gray)
        
        # åº”ç”¨è½»åº¦æ•°æ®å¢å¼º
        pil_image = self.apply_light_augmentation(pil_image)
        
        # è½¬æ¢ä¸ºtensor
        image_tensor = self.transform(pil_image)
        
        # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹ä¸€è‡´çš„æ ‡ç­¾å¤„ç†
        label = str(item['number'])
        # ç§»é™¤å‰å¯¼é›¶ï¼Œä½†ä¿ç•™å•ä¸ª'0'
        label = label.lstrip('0') or '0'
        label_indices = [self.char_to_idx[char] for char in label if char in self.char_to_idx]
        
        return image_tensor, torch.tensor(label_indices, dtype=torch.long)

def collate_fn(batch):
    """ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹å®Œå…¨ä¸€è‡´çš„collateå‡½æ•°"""
    images, labels = zip(*batch)
    images = torch.stack(images)
    
    label_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)
    targets = torch.cat(labels)
    
    batch_size = images.size(0)
    # ğŸ¯ å…³é”®ï¼šä½¿ç”¨ä¸æœ‰æ•ˆæ¨¡å‹ä¸€è‡´çš„åºåˆ—é•¿åº¦è®¡ç®—
    # æ ¹æ®CNNæ¶æ„è®¡ç®—å®é™…è¾“å‡ºé•¿åº¦
    input_lengths = torch.full((batch_size,), 63, dtype=torch.long)  # ç»éªŒå€¼ï¼Œä¸æœ‰æ•ˆæ¨¡å‹ä¸€è‡´
    
    return images, targets, input_lengths, label_lengths

def load_and_prepare_data():
    """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    
    df = pd.read_csv(LABEL_FILE)
    
    train_images = set(os.listdir(TRAIN_IMAGES_DIR))
    val_images = set(os.listdir(VAL_IMAGES_DIR))
    
    train_data = df[df['filename'].isin(train_images)].reset_index(drop=True)
    val_data = df[df['filename'].isin(val_images)].reset_index(drop=True)
    
    print(f"ğŸ¯ è®­ç»ƒé›†: {len(train_data)}ä¸ªæ ·æœ¬")
    print(f"ğŸ¯ éªŒè¯é›†: {len(val_data)}ä¸ªæ ·æœ¬")
    
    return train_data, val_data

def train_improved_crnn():
    """æ”¹è¿›çš„CRNNè®­ç»ƒ"""
    print("ğŸš€ æ”¹è¿›CRNNè®­ç»ƒ - æ–¹æ¡ˆB")
    print("=" * 60)
    print(f"ğŸ¯ åŸºäº79.76%æœ‰æ•ˆæ¶æ„ï¼Œæœ€å°åŒ–æ”¹è¿›")
    print(f"ğŸ“Š è®­ç»ƒé…ç½®ï¼š")
    print(f"   - è®­ç»ƒè½®æ•°: {EPOCHS}")
    print(f"   - æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"   - å­¦ä¹ ç‡: {LEARNING_RATE}")
    print(f"   - éšè—å±‚å¤§å°: {HIDDEN_SIZE} (ä¿æŒä¸å˜)")
    print(f"   - æ—©åœè€å¿ƒå€¼: {EARLY_STOP_PATIENCE}")
    
    # åŠ è½½æ•°æ®
    train_data, val_data = load_and_prepare_data()
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = ImprovedDataset(train_data, CHARS, IMG_HEIGHT, IMG_WIDTH, training=True)
    val_dataset = ImprovedDataset(val_data, CHARS, IMG_HEIGHT, IMG_WIDTH, training=False)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)
    
    # åˆ›å»ºæ¨¡å‹
    model = ImprovedCRNN(IMG_HEIGHT, 1, HIDDEN_SIZE, len(CHARS)).to(DEVICE)
    
    model_size = sum(p.numel() for p in model.parameters()) / 1e6
    print(f"ğŸ“ æ¨¡å‹å¤§å°: {model_size:.1f}M å‚æ•°")
    
    # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹ç›¸ä¼¼çš„ä¼˜åŒ–å™¨é…ç½®
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)  # è½»åº¦æ­£åˆ™åŒ–
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=8, verbose=True)
    
    # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹ä¸€è‡´çš„æŸå¤±å‡½æ•°
    criterion = nn.CTCLoss(blank=BLANK_IDX, zero_infinity=True)
    
    # è®­ç»ƒçŠ¶æ€
    best_val_loss = float('inf')
    patience_counter = 0
    training_history = []
    
    print(f"\nğŸ”¥ å¼€å§‹æ”¹è¿›è®­ç»ƒ...")
    
    for epoch in range(EPOCHS):
        print(f"\nğŸ“… Epoch {epoch+1}/{EPOCHS}")
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_batches = 0
        
        progress_bar = tqdm(train_loader, desc=f'Training')
        for images, targets, input_lengths, target_lengths in progress_bar:
            images = images.to(DEVICE)
            targets = targets.to(DEVICE)
            input_lengths = input_lengths.to(DEVICE)
            target_lengths = target_lengths.to(DEVICE)
            
            optimizer.zero_grad()
            outputs = model(images)
            
            # ğŸ¯ ä¿æŒä¸æœ‰æ•ˆæ¨¡å‹ä¸€è‡´çš„æŸå¤±è®¡ç®—
            loss = criterion(outputs, targets, input_lengths, target_lengths)
            
            if not torch.isnan(loss) and not torch.isinf(loss):
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)  # æ¢¯åº¦è£å‰ª
                optimizer.step()
                
                train_loss += loss.item()
                train_batches += 1
            
            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})
        
        avg_train_loss = train_loss / train_batches if train_batches > 0 else float('inf')
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_batches = 0
        
        print("ğŸ” éªŒè¯ä¸­...")
        with torch.no_grad():
            for images, targets, input_lengths, target_lengths in tqdm(val_loader, desc='Validation'):
                images = images.to(DEVICE)
                targets = targets.to(DEVICE)
                input_lengths = input_lengths.to(DEVICE)
                target_lengths = target_lengths.to(DEVICE)
                
                outputs = model(images)
                loss = criterion(outputs, targets, input_lengths, target_lengths)
                
                if not torch.isnan(loss) and not torch.isinf(loss):
                    val_loss += loss.item()
                    val_batches += 1
        
        avg_val_loss = val_loss / val_batches if val_batches > 0 else float('inf')
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(avg_val_loss)
        current_lr = optimizer.param_groups[0]['lr']
        
        # è®°å½•è®­ç»ƒå†å²
        training_history.append({
            'epoch': epoch + 1,
            'train_loss': avg_train_loss,
            'val_loss': avg_val_loss,
            'lr': current_lr
        })
        
        print(f"ğŸ“Š è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}")
        print(f"ğŸ“Š éªŒè¯æŸå¤±: {avg_val_loss:.4f}")
        print(f"ğŸ“Š å­¦ä¹ ç‡: {current_lr:.6f}")
        
        # æ—©åœå’Œæ¨¡å‹ä¿å­˜
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            torch.save(model.state_dict(), './crnn_improved_best.pth')
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯æŸå¤±: {avg_val_loss:.4f})")
        else:
            patience_counter += 1
            print(f"â³ æ—©åœè®¡æ•°: {patience_counter}/{EARLY_STOP_PATIENCE}")
            
            if patience_counter >= EARLY_STOP_PATIENCE:
                print(f"â¹ï¸ æ—©åœäºç¬¬ {epoch+1} è½®")
                break
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = './crnn_improved_final.pth'
    torch.save(model.state_dict(), final_model_path)
    
    print(f"\nâœ… æ”¹è¿›CRNNè®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“Š æ€»è®­ç»ƒè½®æ•°: {len(training_history)}")
    print(f"ğŸ“ˆ æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
    print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹: ./crnn_improved_best.pth")
    print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹: {final_model_path}")
    
    # ä¿å­˜è®­ç»ƒå†å²
    history_file = 'training_history_improved.csv'
    pd.DataFrame(training_history).to_csv(history_file, index=False)
    print(f"ğŸ“Š è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_file}")

if __name__ == '__main__':
    train_improved_crnn() 